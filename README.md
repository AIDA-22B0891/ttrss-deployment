# NewsHarvestR - ETL Pipeline для обработки новостей из TT-RSS с использованием YandexGPT

NewsHarvestR — это комплексное программное решение для автоматического сбора, интеллектуального анализа и визуализации новостного контента. Проект представляет собой полноценный ETL-пайплайн, разработанный как R-пакет, который интегрирует современные технологии: от RSS-агрегатора и нейросетевых моделей до баз данных и веб-дашбордов. Его модульная архитектура позволяет гибко адаптироваться под различные нужды мониторинга информационного поля.

## Цель проекта

Главной целью проекта является полная автоматизация цикла работы с новостями — от подписки на источники до получения готовых аналитических инсайтов. В отличие от ручного просмотра лент или простых агрегаторов, NewsHarvestR самостоятельно извлекает непрочитанные новости из системы TT-RSS (Tiny Tiny RSS), проводит их глубокий семантический анализ с помощью YandexGPT, структурированно сохраняет обогащенные данные в PostgreSQL и предоставляет интерактивный дашборд для исследования результатов. Это позволяет исследователям, аналитикам и IT-специалистам эффективно вычленять и классифицировать значимые события и тренды из огромного потока информации, экономя время и снижая когнитивную нагрузку.

## Функции и модули

### 1. API-клиент для TT-RSS ([`R/ttrss_client.R`](R/ttrss_client.R:1))

Реализован модуль с использованием библиотеки `httr2`, который обеспечивает:

- Авторизацию через API и получение `session_id` для последующих запросов
- Получение непрочитанных (fresh) новостей из всех лент
- Конвертацию JSON данных в R DataFrame
- Функцию отметки новостей как прочитанных

### 2. Клиент YandexGPT ([`R/llm_client.R`](R/llm_client.R:1))

Разработан модуль для взаимодействия с Yandex Cloud Foundation Models с настроенным системным промптом для выполнения трех задач за один проход:

- Классификации текста (короткий тег, максимум 2 слова)
- Суммаризации (короткое содержание, максимум 1 предложение)
- Оценки важности для IT (число 1-10)

### 3. Модуль хранения данных ([`R/db_storage.R`](R/db_storage.R:1))

Разработан модуль для:

- Подключения к PostgreSQL базе данных
- Создания таблицы `news_analysis` при необходимости
- Сохранения результатов анализа новостей в базу данных с защитой от дублирования
- Обеспечения безопасности через параметризованные запросы

### 4. Модуль очистки текста ([`R/text_cleaner.R`](R/text_cleaner.R:1))

Разработан модуль для:

- Удаления HTML тегов, скриптов и стилей из текста новостей
- Очистки текста от лишних пробелов
- Подготовки текста для корректной обработки LLM и обеспечения качества входных данных

### 5. Основной пайплайн ([`R/pipeline.R`](R/pipeline.R:1))

Создан управляющий скрипт, который:

- Объединяет все компоненты системы
- Настроена работа с переменными окружения (.env) для безопасности ключей API
- Реализована интеграция всех компонентов
- Внедрена обработка ошибок и логирование процесса
- Обеспечивает обработку указанного количества новостей за один запуск

### 6. Аналитический дашборд ([`R/run_dashboard.R`](R/run_dashboard.R:1) и [`inst/dashboard/app.R`](inst/dashboard/app.R:1))

Разработан интерактивный дашборд с визуализацией обработанных новостей из базы данных, включающий:

- КПЭ (общее количество новостей, средняя оценка, топ категории)
- Временную динамику публикаций
- Распределение оценок релевантности
- Таблицу последних новостей с возможностью фильтрации по дате, категории и оценке
- Часовое распределение новостей
- Тепловую карту по дням и категориям

### 7. MCP сервер ([`mcp/server.py.txt`](mcp/server.py.txt:1))

Реализован сервер MCP (Model Context Protocol) для взаимодействия с TT-RSS, обеспечивающий:

- Инструменты для получения активных функций
- Инструменты для авторизации в TT-RSS
- Инструменты для поиска заголовков новостей
- Безопасность транспорта и проверку хостов

## Детальное описание пайплайна

### Общая архитектура

Пайплайн построен по принципам модульности и отказоустойчивости. Он автоматически, без участия человека, выполняет полный цикл: получение "сырых" новостей из TT-RSS → их очистка → интеллектуальный анализ с помощью YandexGPT → сохранение структурированных результатов в PostgreSQL → отметка о прочтении. Процесс может запускаться по расписанию (например, через cron или системный таймер) и обрабатывает заданное количество новостей за итерацию, что делает систему управляемой и ресурсоэффективной. Все действия подробно логируются, обеспечивая полную наблюдаемость (observability) за работой системы.

### Процесс обработки

1. **Инициализация**:
   - Загрузка конфигурации из защищенного файла .env файла
   - Установка соединения с API TT-RSS и аутентификация (получение session_id)
   - Подключение к целевой базе данных PostgreSQL и гарантия существования таблицы news_analysis

2. **Получение новостей**:
   - Запрос непрочитанных новостей из TT-RSS (ограничение по количеству)
   - Проверка наличия новых новостей

3. **Обработка каждой новости**:
   - Очистка текста от HTML-разметки с помощью модуля `text_cleaner.R`
   - Классификация, суммаризация и оценка важности с помощью YandexGPT
   - Сохранение результатов в базу данных `news_analysis` с проверкой на дубликаты
   - Отметка новости как прочитанной в TT-RSS

4. **Обработка ошибок и лоигрование**:
   - На каждом шаге реализованы tryCatch-блоки. Ошибка (например, недоступность API YandexGPT) не ломает весь цикл — информация об ошибке записывается в лог, а пайплайн переходит к следующей новости.
   - Логирование ошибок для последующего анализа
   - Между обработкой отдельных новостей добавлена короткая пауза (Sys.sleep()) для соблюдения лимитов запросов к внешним AP

5. **Корректное завершение**:
   - По окончании цикла все соединения с базами данных аккуратно закрываются
   - В лог выводится итоговый отчет: количество успешно обработанных и пропущенных из-за ошибок новостей

### Используемые переменные окружения

- `TTRSS_URL`, `TTRSS_USER`, `TTRSS_PASS` - параметры для подключения к TT-RSS
- `YA_FOLDER_ID`, `YA_API_KEY` - параметры для доступа к YandexGPT
- `DB_HOST`, `DB_PORT`, `DB_NAME`, `DB_USER`, `DB_PASS` - параметры для подключения к PostgreSQL
- `PIPELINE_ITEMS_COUNT` - количество новостей для обработки за один запуск (по умолчанию 5)
- `PIPELINE_INTERVAL` - интервал между запусками пайплайна в секундах (по умолчанию 300)

## Архитектура

### Общая схема

Система построена по модульной архитектуре с использованием Docker-контейнеров. Основные компоненты включают:

- **TT-RSS сервер**: Специализированный агрегатор, отвечающий за подписку на RSS-ленты и предоставление новостей через API.
- **PostgreSQL база данных**: Изолированная база данных, предназначенная исключительно для хранения обогащенных данных, полученных в результате работы пайплайна (таблица news_analysis).
- **Пайплайн на R**: Ядро системы, развернутое в среде R. Выполняет роль оркестратора и процессора данных.
- **Дашборд на Shiny**: Легковесное веб-приложение, подключенное к аналитической БД для визуализации.
- **MCP сервер**: Опциональный компонент, предоставляющий API TT-RSS как инструмент для LLM через стандартный протокол.
  
### Подробная структуры базы даннхы TT-RSS

Основное хранилище данных системы TT-RSS организовано в несколько ключевых таблиц внутри базы данных PostgreSQL. Это сложная схема, которая поддерживает все функции агрегатора: пользователей, ленты, статьи, настройки, фильтры и теги. Ваш ETL-пайплайн взаимодействует с этой схемой через API, но понимание её глубины важно для дальнейшей интеграции или расширения системы. В соответствии с лучшими практиками PostgreSQL, все таблицы расположены в схеме по умолчанию public. Далее распианы сами таблицы, их назначение и связи с другими таблицами:
Таблица	Назначение	Связи с другими таблицами

- ttrss_feeds: Ядро системы. Хранит все RSS-ленты, на которые подписан пользователь или система. Содержит настройки обновления (update_interval), URL, название и связь с категориями (cat_id). Связана с ttrss_feed_categories (категории), ttrss_user_entries (статьи пользователя).
- ttrss_entries: Центральное хранилище контента. Содержит все статьи, полученные со всех RSS-лент. У каждой записи есть уникальный guid, заголовок (title), ссылка (link), контент (content), дата публикации (updated) и автор (author). Это таблица общего пула статей. Её id ссылается на ttrss_user_entries.ref_id. Это позволяет разделять один и тот же текст статьи между разными пользователями.
- ttrss_user_entries: Связующее звено между пользователем и статьей. Отслеживает состояние статьи для конкретного пользователя: прочитана ли она (unread), помечена (marked), оценка (score). Поле ref_id ссылается на общую статью в ttrss_entries, а feed_id — на её источник. Ключевая таблица для API. Запрос getHeadlines возвращает данные на основе связи ref_id и состояния unread.
- ttrss_users: Учетные записи. Содержит логины, хэши паролей, email и уровень доступа пользователей системы. Практически все таблицы (ttrss_feeds, ttrss_user_entries, ttrss_filters2) имеют внешний ключ owner_uid к этой таблице.
- ttrss_feed_categories: Иерархия категорий лент. Позволяет пользователю организовывать свои подписки в папки. Поддерживает вложенность через parent_cat. Связана с ttrss_feeds.cat_id.

### Важное замечание об архитектуре

**База данных с проанализированными новостями изолирована и находится на отдельном инстансе.** Это обеспечивает:

- Повышенную безопасность: Компрометация аналитической панели не затрагивает основную систему агрегации новостей.
- Независимость и стабильность: Работа ресурсоемкого ETL-пайплайна, логика анализа и обновления схемы данных не влияют на стабильность и скорость работы RSS-агрегатора.
- Удобство администрирования: Целевую базу данных можно резервировать, масштабировать и оптимизировать под аналитические запросы независимо от инфраструктуры источника данных.
- Четкое разделение ответственности: TT-RSS отвечает только за сбор и первичное хранение новостей, а NewsHarvestR — за их интеллектуальный анализ, обогащение и хранение результатов в собственной, оптимизированной для анализа схеме.

### Схема взаимодействия компонентов
![](./images/arch.png)

#### Пример структуры таблицы

Далее указаны поля, тип данных, подробное описание и названение, а также ограничения и особенности.
- id: SERIALАвтоинкрементный первичный ключ. Технический уникальный идентификатор записи в рамках нашей аналитической базы. Значение генерируется автоматически при вставке новой строки и гарантирует целостность и порядок записей. PRIMARY KEY
- news_id: TEXT, Уникальный глобальный идентификатор новости из TT-RSS. Это ключевое поле для обеспечения идемпотентности пайплайна. Оно предотвращает дублирование одной и той же новости в таблице, даже если она была повторно получена из источника. UNIQUE, NOT NULL
- title: TEXT, Оригинальный заголовок статьи, полученный из RSS-ленты. Хранится в исходном виде, что позволяет проводить точный поиск и верификацию.	
- link: TEXT, Прямая URL-ссылка на оригинальную публикацию. Позволяет пользователю или системе быстро перейти к первоисточнику для получения полной информации.	
- published_at: TIMESTAMP, Дата и время публикации новости в её оригинальном источнике. Критически важное поле для анализа временных трендов, построения графиков публикационной активности и фильтрации новостей по периоду.	INDEX (рекомендуется)
- category: TEXT, Семантическая категория, присвоенная нейросетью YandexGPT. Это результат интеллектуальной классификации (например, "Кибербезопасность", "Запуск ракеты", "Экономика"). Позволяет автоматически группировать и структурировать разнородный новостной поток.	
- summary: TEXT, Краткое, содержательное изложение сути статьи, сгенерированное YandexGPT в ходе процесса автоматической суммаризации. Позволяет мгновенно уловить основную мысль, не читая полный текст.	
- score:	INTEGER, Оценка релевантности и важности новости для IT-аудитории, вычисленная YandexGPT. Представляет собой числовое значение в диапазоне от 1 до 10, где 10 — максимальная важность. Это ключевой показатель для приоритизации и ранжирования материалов в дашборде. CHECK (score >= 1 AND score <= 10)
- created_at: TIMESTAMP, Метка времени создания записи в нашей аналитической базе. Автоматически фиксирует момент, когда новость прошла полный цикл ETL (извлечение, трансформация, загрузка). Важно для аудита работы системы и анализа её производительности. DEFAULT CURRENT_TIMESTAMP

### Общая схема данных

Для полноты документации и демонстрации реальной инсталляции ниже приведен фрагмент SQL-кода (DDL - Data Definition Language), который определяет структуру некоторых ключевых таблиц. Этот код автоматически генерируется при развертывании системы и находится в репозитории проекта (database-schema/full_schema.sql).

```
--
-- Name: ttrss_entries; Type: TABLE; Schema: public;
--

CREATE TABLE public.ttrss_entries (
    id integer NOT NULL,
    title text NOT NULL,
    guid text NOT NULL,
    link text NOT NULL,
    updated timestamp without time zone NOT NULL,
    content text NOT NULL,
    content_hash character varying(250) NOT NULL,
    cached_content text,
    no_orig_date boolean DEFAULT false NOT NULL,
    date_entered timestamp without time zone NOT NULL,
    date_updated timestamp without time zone NOT NULL,
    num_comments integer DEFAULT 0 NOT NULL,
    comments character varying(250) DEFAULT ''::character varying NOT NULL,
    plugin_data text,
    tsvector_combined tsvector,
    lang character varying(2),
    author character varying(250) DEFAULT ''::character varying NOT NULL
);

--
-- Name: ttrss_user_entries; Type: TABLE; Schema: public;
--

CREATE TABLE public.ttrss_user_entries (
    int_id integer NOT NULL,
    ref_id integer NOT NULL,
    uuid character varying(200) NOT NULL,
    feed_id integer,
    orig_feed_id integer,
    owner_uid integer NOT NULL,
    marked boolean DEFAULT false NOT NULL,
    published boolean DEFAULT false NOT NULL,
    tag_cache text NOT NULL,
    label_cache text NOT NULL,
    last_read timestamp without time zone,
    score integer DEFAULT 0 NOT NULL,
    last_marked timestamp without time zone,
    last_published timestamp without time zone,
    note text,
    unread boolean DEFAULT true NOT NULL
);

--
-- Name: ttrss_feeds; Type: TABLE; Schema: public;
--

CREATE TABLE public.ttrss_feeds (
    id integer NOT NULL,
    owner_uid integer NOT NULL,
    title character varying(200) NOT NULL,
    cat_id integer,
    feed_url text NOT NULL,
    icon_url character varying(250) DEFAULT ''::character varying NOT NULL,
    update_interval integer DEFAULT 0 NOT NULL,
    purge_interval integer DEFAULT 0 NOT NULL,
    last_updated timestamp without time zone,
    last_unconditional timestamp without time zone,
    last_error text DEFAULT ''::text NOT NULL,
    last_modified text DEFAULT ''::text NOT NULL,
    favicon_avg_color character varying(11) DEFAULT NULL::character varying,
    favicon_is_custom boolean,
    site_url character varying(250) DEFAULT ''::character varying NOT NULL,
    auth_login character varying(250) DEFAULT ''::character varying NOT NULL,
    parent_feed integer,
    private boolean DEFAULT false NOT NULL,
    auth_pass text DEFAULT ''::text NOT NULL,
    hidden boolean DEFAULT false NOT NULL,
    include_in_digest boolean DEFAULT true NOT NULL,
    rtl_content boolean DEFAULT false NOT NULL,
    cache_images boolean DEFAULT false NOT NULL,
    hide_images boolean DEFAULT false NOT NULL,
    cache_content boolean DEFAULT false NOT NULL,
    last_viewed timestamp without time zone,
    last_update_started timestamp without time zone,
    last_successful_update timestamp without time zone,
    update_method integer DEFAULT 0 NOT NULL,
    always_display_enclosures boolean DEFAULT false NOT NULL,
    order_id integer DEFAULT 0 NOT NULL,
    mark_unread_on_update boolean DEFAULT false NOT NULL,
    update_on_checksum_change boolean DEFAULT false NOT NULL,
    strip_images boolean DEFAULT false NOT NULL,
    view_settings character varying(250) DEFAULT ''::character varying NOT NULL,
    pubsub_state integer DEFAULT 0 NOT NULL,
    favicon_last_checked timestamp without time zone,
    feed_language character varying(100) DEFAULT ''::character varying NOT NULL,
    auth_pass_encrypted boolean DEFAULT false NOT NULL
);
```

### Безопасность и надежность

В проект заложены принципы Secure by Design и Production-Ready Development:

- Никаких хардкодированных секретов: Все пароли, ключи API и чувствительные URL хранятся в переменных окружения, загружаемых из .env файла, который исключен из Git (.gitignore).
- Защита от инъекций: Все SQL-запросы используют параметризованные выражения (DBI::dbSendQuery), что нейтрализует риски SQL-инъекций.
- Устойчивость к сбоям: Многоуровневая обработка ошибок (tryCatch) гарантирует, что временная недоступность одного сервиса (YandexGPT, сеть) не приведет к потере данных или аварийной остановке всего пайплайна.
- Архитектурная изоляция: Разделение БД и сервисов через Docker-контейнеры создает естественные барьеры безопасности и повышает отказоустойчивость системы в целом.
  
## Тестирование

Проект включает полноценный набор модульных и интеграционных тестов, что свидетельствует о высоком уровне зрелости кодовой базы.

### Структура тестов

Проект включает комплексные тесты для всех основных модулей, реализованные с использованием фреймворка `testthat`:

- **Тесты для модуля хранения данных** (`tests/testthat/test-db-storage.R`): Проект включает полноценный набор модульных и интеграционных тестов, что свидетельствует о высоком уровне зрелости кодовой базы.
- **Тесты для клиента YandexGPT** (`tests/testthat/test-llm-client.R`): Тестирует логику клиента YandexGPT на различных сценариях: обработка коротких текстов, реакция на имитацию сетевых ошибок и таймаутов, парсинг ответов модели.
- **Тесты для модуля очистки текста** (`tests/testthat/test-text-cleaner.R`): Убеждается, что модуль корректно удаляет сложные HTML-конструкции, скрипты, стили и нормализует пробельные символы в тексте.
- **Тесты для клиента TT-RSS** (`tests/testthat/test-ttrss-client.R`)Проверяет базовые функции клиента TT-RSS: успешность авторизации и получения session_id, корректность парсинга ответа со списком новостей, работу функции отметки как прочитанной.
- **Тесты для основного пайплайна** (`tests/testthat/test-pipeline.R`): Интеграционные тесты, которые проверяют взаимодействие всех модулей в миниатюре, включая обработку ошибок и логирование.

### Запуск тестов

Для поддержания качества кода и регрессионного тестирования используется стандартный рабочий процесс R:

```R
# Установка зависимостей
install.packages("testthat")

# Запуск всех тестов
devtools::test()
```

### Покрытие кода

Для количественной оценки качества тестов используется инструмент covr. Запуск скрипта generate_coverage_report.R генерирует детальный отчет в формате HTML, который наглядно показывает, какие строки кода в каждом модуле были задействованы при выполнении тестов, а также сводный отчет в JSON, пригодный для интеграции в CI/CD-пайплайны. Это позволяет целенаправленно улучшать тестовое покрытие.

